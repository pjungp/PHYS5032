{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Numerical Integration\n",
    "A frequent task is to evaluate integrals of functions for which no stem function exists or which is given in terms of points at discrete locations. \n",
    "<br>\n",
    "## Trapezoidal Rule\n",
    "We start with probably the most simple rule, which is known as the Trapezoidal rule. The idea is simple:\n",
    "<img src=\"figures/trapezoid.png\" style=\"width:500px;height:500px;\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The interval over which the function is to integrated is divided up into $N$ bins ranging from $x_k=a+kh$ to $x_{k+1}=a+(k+1)h$, where $k=0,1,\\ldots,N$. The lower and upper limits of integration are $a=x_0$ and $b=x_N=a+Nh$. The integral over each bin is approzimated by a trapzoid as shown above, i.e. \n",
    "\n",
    "$$I_k = h \\cdot f(x_k)+{1 \\over 2}h \\cdot (f(x_{k+1})-f(x_k)) \n",
    "              = {1 \\over 2}h \\left ( f(x_k) + f(x_{k+1}) \\right ) \\,.$$\n",
    "              \n",
    "For the entire integral we add those contributions from $k=0$ to $k=N-1$ (last trapezoid starts at $x_{N-1}$). The results is\n",
    "\n",
    "$$I(a,b) \\approx \\sum_{k=0}^{N-1} I_k = \\sum_{k=0}^{N-1}{1 \\over 2}h \\left ( f(x_k) + f(x_{k+1}) \\right ) \n",
    "= h \\left ( {1 \\over 2}f(a) + \\sum_{k=1}^{N-1}f(x_{k}) + {1 \\over 2}f(b)\\right ) $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Python program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted integral = 2.0333e-01 , error = 3.330e-03\n"
     ]
    }
   ],
   "source": [
    "from numpy import arange\n",
    "# define the function to be integrated\n",
    "def f(x):\n",
    "    f=x**4\n",
    "    return f\n",
    "\n",
    "# integration interval and bin size\n",
    "a=0;b=1;N=10\n",
    "h=(b-a)/N\n",
    "\n",
    "# I execute first the sum in the Trapezoid rule and then add the contributions from\n",
    "# the endpoints. \n",
    "x=arange(a+h,b,h)\n",
    "y=f(x)\n",
    "integral1=0.5*h*(f(a)+f(b))+sum(y)*h\n",
    "\n",
    "# compact notation\n",
    "# integral2=0.5*h*(f(a)+f(b))+sum(f(arange(a+h,b,h)))*h\n",
    "\n",
    "# error obtained by comparing with the analytically calculated integral\n",
    "error_abs = abs(0.2 - integral1)\n",
    "print(\"predicted integral = %5.4e , error = %5.3e\"%(integral1, error_abs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the error first decreases with increasing N but then starts to increase again. Why does that happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximation error\n",
    "As discussed earlier there are two types of errors that plague numerical calculations, a) ***approximation errors***, and b) ***rounding errors***. ***Approximation errors*** are due to the fact that the mathematical expressions which we use to calculate the integral are approximate. ***Rounding errors*** are die to the reppresentation of mumbers in your computer as finite strings. \n",
    "\n",
    "To estimate the approximation error we have to derive the Trapezoidal rule now in a more systematic way through Taylor expansions - this way we know what we miss. Like before we split the integration interval in small bins ranging from $x_k$ to $x_{k+1}$, calculate the integral over the small bin, and then add the parts. We consider the interval \n",
    "$I_{k}\\equiv[x_{k} : x_{k+1}]$. We perform a Taylor expansion of the function $f(x)$ for the values of $f$ in $I_{k}$ around $x_{k}$\n",
    "\n",
    "$$f(x) = f(x_{k})+f^\\prime (x_{k}) (x - x_{k}) + {1 \\over 2}f^{\\prime\\prime}(x_{k})(x - x_{k})^2 + \\ldots$$\n",
    "\n",
    "Such polynomial can be integrated over the interval $I_{k-1}$ and we find by elementary steps\n",
    "\n",
    "$$\\int_{x_{k}}^{x_{k+1}} f(x)dx = hf(x_{k}) +{1 \\over 2}h^2 f^\\prime (x_{k})\n",
    "                                       +{1 \\over 6}h^3 f^{\\prime\\prime}(x_{k}) + O(h^4)$$\n",
    "                                       \n",
    "Now we use a trick. We expand the function $f$ around the endpoint $x_{k+1}$ of the interval to approximate its values in $I_{k}$, i.e.\n",
    "\n",
    "$$f(x) = f(x_{k+1})+f^\\prime (x_{k+1}) (x - x_{k+1}) + {1 \\over 2}f^{\\prime\\prime}(x_{k+1})(x - x_{k+1})^2 +\\ldots$$\n",
    "\n",
    "which also can integrated over $I_{k}$ easily, yielding \n",
    "\n",
    "$$\\int_{x_{k}}^{x_{k+1}} f(x)dx = hf(x_{k+1}) -{1 \\over 2}h^2 f^\\prime (x_{k+1})\n",
    "                                       +{1 \\over 6}h^3 f^{\\prime\\prime}(x_{k+1}) + O(h^4)$$\n",
    "                                       \n",
    "Adding the two Taylor expansions and dividing by $2$, we find\n",
    "\n",
    "$$\\int_{x_{k}}^{x_{k+1}} f(x)dx = {1 \\over 2} h \\left ( f(x_{k}) + f(x_{k+1}) \\right )\n",
    "                                       +{1 \\over 4}h^2 \\left ( f^\\prime (x_{k}) - f^\\prime (x_{k+1}) \\right )\n",
    "                                       +{1 \\over 12}h^3 \\left ( f^{\\prime\\prime}(x_{k} + f^{\\prime\\prime}(x_{k+1}) \\right ) + O(h^4)$$\n",
    "                                       \n",
    "Now we add all the pieces together, canceling the $h^2$-terms except for the first and last one, and we find\n",
    "\n",
    "$$\\int_{a}^{b} f(x)dx = {1 \\over 2}h \\sum_{k=0}^{N-1} \\left ( f(x_{k}+f(x_{k+1}) \\right ) \n",
    "+{1 \\over 4}h^2 \\left ( f^\\prime (a) - f^\\prime (b) \\right ) \n",
    "+{1 \\over 12}h^3 \\sum_{k=1}^N \\left ( f^{\\prime\\prime}(x_{k}) + f^{\\prime\\prime}(x_{k+1}) \\right ) +O(h^4) $$\n",
    "\n",
    "The first term on the rhs represents the Trapezoidal rule with corrections of the order $h^2$. The remaining terms describe deviations from the correct result and hence represent the ***approximation error***. The second term is of the order $h^2$ and hence smaller than the leading order term representing Trapezoidal rule. The third term on\n",
    "the right hand side appears on the first glance a term of the order $h^3$ and hence even smaller than the previous term, but it is not. The sum over the N terms results in factor of $N\\propto 1/h$ making this term of the same order than the previous term. We make this argument now more quantitative by using the Trapezoidal rule for integrating $f^{\\prime\\prime}(x)$ which reads in leading order of $h$\n",
    "\n",
    "$$\\int_a^b f^{\\prime\\prime}(x)dx = {1 \\over 2}h \\sum_{k=0}^{N-1} \\left ( f^{\\prime\\prime}(x_{k}) + f^{\\prime\\prime}(x_{k+1}) \\right ) + O(h^2) = f^{\\prime} (b) - f^{\\prime} (a) $$\n",
    "\n",
    "Hence\n",
    "\n",
    "$${1 \\over 12}h^3 \\sum_{k=0}^{N-1} \\left ( f^{\\prime\\prime}(x_{k}) + f^{\\prime\\prime}(x_{k+1})\\right ) \n",
    "= {1 \\over 6}h^2 \\cdot {1 \\over 2}h \\sum_{k=0}^{N-1} \\left ( f^{\\prime\\prime}(x_{k}) + f^{\\prime\\prime}(x_{k+1})\\right ) \n",
    "= {1 \\over 6}h^2 \\left ( f^\\prime (b) - f^\\prime (a) \\right ) \n",
    "= - {1 \\over 6}h^2 \\left ( f^\\prime (a) - f^\\prime (b) \\right )$$\n",
    "\n",
    "Combining with the other terms we find the final Euler-McLaurin formula\n",
    "\n",
    "$$\\boxed{\\int_{a}^{b} f(x)dx = {1 \\over 2}h \\sum_{k=0}^{N-1} \\left ( f(x_{k}+f(x_{k+1}) \\right ) +\n",
    "{1 \\over 12}h^2 \\left ( f^\\prime (a) - f^\\prime (b) \\right ) + O(h^4) }$$\n",
    "\n",
    "Note that this equation is only useful if we do know the derivative of the function to be integrated. Often this is not the case, for example if we have the function f only as a set of discrete points. In this case we will discuss direct methods to estimate the error, which does not require the derivative. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Euler McLaurin Formula\n",
    "The Euler McLaurin formula provides us with the approximation error of the Trapezoidal rule. It tells us that the error is of the order of $h^2$ and hence is smaller than the leading order term. \n",
    "\n",
    "The leading order term is actually of the order $h^0$, since the sum provides N terms of the order $1$ resulting in a factor of about $N$ which is proportional to $1/h$ since $h = (a-b)/N$, or $N = (a-b)/h$. \n",
    "\n",
    "Most important, to apply this formula we need to know the derivatives of the function to be integrated at the end poinst. In case we know that function only at discrete points, we cannot use this error estimate. Let's test this formula. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error McLaurin = 3.3333333333e-13 , actual error = 3.3287261836e-13, binsize = 1.000e-06\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "# define the function to be integrated\n",
    "def f(x):\n",
    "    f=(x)**4\n",
    "    return f\n",
    "#\n",
    "# integration interval and bin size\n",
    "#\n",
    "a=0.0;b=1.0;N=1000000\n",
    "h=(b-a)/N\n",
    "#\n",
    "# I execute first the sum in the Trapezoid rule and then add the contributions from\n",
    "# the endpoints. \n",
    "#\n",
    "x=np.arange(a+h,b,h,dtype='float64')\n",
    "y=f(x)\n",
    "integral=0.5*h*(f(a)+f(b))+sum(y)*h\n",
    "\n",
    "# error\n",
    "error_abs = abs(0.2 - integral)\n",
    "error_mc = abs((1/12)*(h**2)*(0 - 4))\n",
    "print(\"Error McLaurin = %1.10e , actual error = %1.10e, binsize = %5.3e\"%(error_mc, error_abs,h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is important. It tells us that the approximation error decreases by a factor of $4$ if we double the number of bins. This insight is the basis for *adaptive* methods which are used to compute an integral for a specified accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "### Round-off error vs approximation error\n",
    "Experimenting with the python program above, we find that if the number of steps is $10^6$, the absolute error is about 10^{-13}. Further increase of $N$ results in\n",
    "an increase of error and stochastic behavior. This is the point, where round-off errors are becoming important. Here is an estimate. We add N numbers which should give us a standard deviation of $\\approx \\epsilon\\sqrt{N} = \\epsilon/\\sqrt{h}$. Using Euler-McLaurin, the algorihtmic error is\n",
    "\n",
    "$$ \\left | {1 \\over 12}h^2 \\left ( f^\\prime (a) - f^\\prime (b) \\right ) \\right | =  \\left | {1 \\over 12}h^2 4 \\right |  = {1 \\over 3}h^2$$\n",
    "\n",
    "The value at which we see mounting round-off errors is when the expected roundoff errors match the algorithmic \n",
    "is given by\n",
    "\n",
    "$$ {1 \\over 3}h^2 = \\epsilon h^{-1/2}$$\n",
    "\n",
    "and hence\n",
    "\n",
    "$$ h = (3\\epsilon)^{2/5} \\approx 1.5\\cdot 10^{-6}, N_{opt}={1 \\over h}=7\\cdot 10^5 $$\n",
    "\n",
    "The estimated minimial error \n",
    "\n",
    "$$ std = \\epsilon /\\sqrt{h} \\approx 8\\cdot 10^{-13} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simpson Rule\n",
    "To avoid accumulation of round-off errors, we can use a more accurate algorithm that uses fewer bins for a required accurace. \n",
    "The Trapezoidal rule is a *2-point* rule, where we use two subsequent points and their functions to approximate the integral over each subinterval. The **Simpson Rule** is a *3-point* rule, where we use three subsequent points. \n",
    "<img src=\"figures/Simpson-1.png\" style=\"width:500px;height:450px;\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic idea is quite simple. The integration interval is divided into $N$ bins starting at $x_k = a + kh$, where $k=0,1,2,\\ldots,N-2,N-1$. Specifically $x_0=a,x_N=b$.\n",
    "We will use three sequential points and we fit a polynomials of second order, i.e.\n",
    "$f(x)\\approx c_2x^2+c_1x+c_0$ through those three points. For each interval the three constants $a,b$ and $c$ are then uniquely determined by\n",
    "<img src=\"figures/Simpson-2.png\" style=\"width:500px;height:450px;\" >\n",
    "\n",
    "$$c_2 = {1 \\over h^2}\\left ( {1 \\over 2} f(x_{k-1}) - f(x_k) + {1 \\over 2}f(x_{k+1} \\right )$$\n",
    "$$c_1 = {1 \\over 2h}\\left ( f(x_{k+1}) - f(x_{k-1}) \\right )$$\n",
    "$$c_0 = f(x_k)$$\n",
    "\n",
    "The function in the interval $[x_{k-1},x_{k+1}]$ is thus approximated by a second order polynomial which can be integrated to obtain an approximation for the integral in this interval\n",
    "\n",
    "$$I_k = \\int_{x_{k-1}}^{x_{k+1}} f(x)dx \\approx {1 \\over 3}h \\left ( f(x_{k-1}) + 4f(x_k) +f(x_{k+1}) \\right ) $$\n",
    "\n",
    "What is left to do now is to add all those values over the entire domain of integration, resulting in\n",
    "\n",
    "$$ I(a,b) = {1 \\over 3}h \\left ( f(a) + 4f(x_1) +f(x_2) +f (x_2) +4f(x_3) + f(x_4) + \\ldots +f(x_{N-2} + 4f(x_{N-1}) + f(b) \\right )$$\n",
    "\n",
    "\n",
    "\n",
    "$$I(a,b) = {1 \\over 3}h \\left ( f(a) + 4\\underbrace{\\sum_{k=1}^{N-1}f(a+kh)}_{k~ \\rm {odd}} + \n",
    "\\underbrace{2\\sum_{k=2}^{N-2}f(a+kh)}_{k~ \\rm{even}} + f(b) \\right )$$\n",
    "\n",
    "By construction, the number of bins $N$ is an even number because we use 2 bins for each sub-integral. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted integral = 0.200013 , error = 1.3333333333e-05, h = 1.0000000000e-01\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# integration with Simpson rule\n",
    "#\n",
    "from numpy import arange,sin,pi\n",
    "# define the function to be integrated\n",
    "def f(x):\n",
    "    f=x**4\n",
    "    return f\n",
    "#\n",
    "# integration interval and bin size\n",
    "#\n",
    "a=0;b=1;N=10\n",
    "h=(b-a)/N\n",
    "#\n",
    "# execute Simpson with array-operations\n",
    "#\n",
    "x_odd=arange(a+h,b,2*h)\n",
    "y_odd=f(x_odd)\n",
    "x_even=arange(a+2*h,b,2*h)\n",
    "y_even=f(x_even)\n",
    "integral=h*(1./3.)*(f(a)+f(b)+4*sum(y_odd)+2*sum(y_even))\n",
    "#\n",
    "abs_error = abs(0.2 - integral)\n",
    "print(\"predicted integral = %5.6f , error = %5.10e, h = %5.10e\"%(integral, abs_error,h))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approximation error\n",
    "A similar calculation as for the Trapezoidal rule can be done for the Simposon rule, resulting in \n",
    "\n",
    "<center> ${\\rm error} = {1 \\over 90}h^4 \\left ( f^{\\prime\\prime\\prime}(a) - f^{\\prime\\prime\\prime}(b) \\right )$\n",
    "\n",
    "which tells us that The Simpson method is a third-order method - two orders better than the Trapezoid rule. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
